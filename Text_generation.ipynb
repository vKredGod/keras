{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generation",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vKredGod/keras/blob/master/Text_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dwBHlyKlPNQZ",
        "colab_type": "code",
        "outputId": "97fec43d-7379-4b42-f875-cebf72033665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Rb0ZO480Rzcd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The train file will be a collection of Sherlock Holmes. This will teach the algorithm how to write <br><br>\n",
        "Opening the file and reading the text length (in characters)"
      ]
    },
    {
      "metadata": {
        "id": "jBIrQIzBPgjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a7236e1-b7e7-43a8-8844-6273f306761e"
      },
      "cell_type": "code",
      "source": [
        "text = open('train_text.txt', 'r').read().lower()\n",
        "print('text length', len(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text length 561835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "46PoXioXSQar",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Printing the first 300 characters of it."
      ]
    },
    {
      "metadata": {
        "id": "bqtz-JKgRVj0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4f089f6b-53ad-4760-9f41-0c42adc52c25"
      },
      "cell_type": "code",
      "source": [
        "print(text[:300])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ï»¿adventure i. a scandal in bohemia\n",
            "\n",
            "i.\n",
            "\n",
            "to sherlock holmes she is always the woman. i have seldom heard\n",
            "him mention her under any other name. in his eyes she eclipses\n",
            "and predominates the whole of her sex. it was not that he felt\n",
            "any emotion akin to love for irene adler. all emotions, and that\n",
            "one p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uq29ANoTS0Kf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transforming letters into integers (For the algorithm to learn)"
      ]
    },
    {
      "metadata": {
        "id": "ZeixnE4LSuLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a7903d60-9d5b-44cb-9eb6-926ee7f5cadb"
      },
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars: ', len(chars))\n",
        "\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars:  56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mv9rqpJCTjmn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here I will split the text into \"subsequences\". This means that I will use things such as \"\\n\" or double quotes to make the algorithm understand where it needs to create a new line or end a phrase."
      ]
    },
    {
      "metadata": {
        "id": "q4kvqekNTcMP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd401f4b-5792-4842-b7b1-b4df7a3c7327"
      },
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  \n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "    \n",
        "print('nb sequences:', len(sentences))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 187265\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "d2liUNJhTgu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7548f41e-308c-4fb9-d63f-3bcef1f21700"
      },
      "cell_type": "code",
      "source": [
        "print(sentences[:3])\n",
        "print(next_chars[:3])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeffadventure i. a scandal in bohemia\\n\\ni.\\n\\n', 'venture i. a scandal in bohemia\\n\\ni.\\n\\nto ', 'ture i. a scandal in bohemia\\n\\ni.\\n\\nto she']\n",
            "['t', 's', 'r']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rZQv2PvwT03V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "  \n",
        "    for t, char in enumerate(sentence):\n",
        "      \n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NWz6q_QkT6da",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "eb98cb75-3acf-4aa9-8576-662d15988cb3"
      },
      "cell_type": "code",
      "source": [
        "print(x[:3])\n",
        "print(y[:3])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[False False False ... False False  True]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [ True False False ... False False False]\n",
            "  [ True False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False  True False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "[[False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False  True False False False\n",
            "  False False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False  True False False False False\n",
            "  False False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False  True False False False False False\n",
            "  False False False False False False False False]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1TLuqOhEUQOz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating the model\n",
        "\n",
        "This is the \"brain\", or the neural structure of the algorithm. It is the part that processes the text and produces everything."
      ]
    },
    {
      "metadata": {
        "id": "fuO5OoguUjh5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cilh8E2MUset",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = RMSprop(lr=0.01)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a2aJ3m6PUyXw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**These are functions that will help me feed the text to the algorithm. These were taken from the official Keras python github repository. https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py **"
      ]
    },
    {
      "metadata": {
        "id": "3dIjhdobU-QP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-EcsU5JTVBr0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def on_epoch_end(epoch, logs):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ySpXS_AVVXAz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Saving the neuron values into a file."
      ]
    },
    {
      "metadata": {
        "id": "GSiReajYVFdz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"weights.hdf5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xnurAXCGVals",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=1, min_lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vimhRzGfVjxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "callbacks = [print_callback, checkpoint, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2zNtatKQVmFt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Training the model.**\n",
        "\n",
        " The algorithm ends here. This code snippet will start the learning process of the algorithm. It takes a good ammount of time. While it is training, we can see the progress, which it very cool. <br><br>\n",
        " Once done, The program will call the following code when done: print_callback, checkpoint and reduce_lr, that were previously defined. This will save the neuron and the model (brain) structure.\n"
      ]
    },
    {
      "metadata": {
        "id": "ByiFsIhxVxY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3828
        },
        "outputId": "17795bc4-cfad-49b4-9882-b4c10f76677f"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/5\n",
            "187265/187265 [==============================] - 216s 1ms/step - loss: 1.9980\n",
            "\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"out five ft. seven in. in height;\n",
            "strong\"\n",
            "out five ft. seven in. in height;\n",
            "strong the strance of the man which the strange and and the strance which the man which had seemed to the stranced to the fact and the charted and the man when he sall the lanced the man and the strong had seemed the man which the past the street of the man and and house the spall the street to the strance the past the stranced to the forser the strance which had seemed the strance to the street and the\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"out five ft. seven in. in height;\n",
            "strong\"\n",
            "out five ft. seven in. in height;\n",
            "strong had the factle, and to saig the stranked the recappens the that in a getter. the machancely with a\n",
            "contice. i the recaltion. i can with a shermous stanth whom he dades, me have but had real and sight the strance which have ress of the wanded the ong the treesemed the forsed and spretter of the strance. when i had allestily to the man and and couldng to the fildow\n",
            "suspention. who has not head to s\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"out five ft. seven in. in height;\n",
            "strong\"\n",
            "out five ft. seven in. in height;\n",
            "strong\n",
            "for ers htas allony, folflance, suegact in?\"\n",
            "\n",
            "\"ne! a\n",
            "lighe, and\n",
            "he wat of hadd remuck.\"\n",
            "\n",
            "\"hiwh both sight witht that the sigch no scan, wouse a deavens sight, to hous reou whatlest denginge\" 'm. has hanchow\n",
            "prepuliaoast did\n",
            "which i had sedses thries winding in that\n",
            "nees washed the magten\n",
            "fantible father was of sfot haterpescents a swance! of asway, and sumnes aly grear papeds storts. and spegpal \n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"out five ft. seven in. in height;\n",
            "strong\"\n",
            "out five ft. seven in. in height;\n",
            "stronge inberbabced herd infuittor. had been bus of they gort\n",
            "here,\n",
            "hat seare\n",
            "botked, rousturifuth way,\n",
            "yat or.\"\n",
            "\n",
            "i hald cou'sigg, the forseretesbing but a\n",
            "seact dnists now how ofthial.\" he may's cosk,\" nlo brewan noman's to se,\" i dnay you in liscinul\n",
            "to a'y, in leattovess lack to ?.\n",
            "\n",
            "wewe and onchening in has.g, wats tanking that an\n",
            "faledt\n",
            "sined had coafes deam you, love, arl. gaves uptil\n",
            "sdaved,  mr.\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.99798, saving model to weights.hdf5\n",
            "Epoch 2/5\n",
            "187265/187265 [==============================] - 214s 1ms/step - loss: 1.6586\n",
            "\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"f not only a\n",
            "very capable performer but \"\n",
            "f not only a\n",
            "very capable performer but in the wooden with a came to the woold with a start of the street with a street of the window with a great of the word which i have no man. i was see to me with a seemed to the patier which we should of the winded with a trist in the wooden with a street and well in the well will the lestred of the way well that i was a start of the way which we have no the all that i was a palled to the proter, a\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"f not only a\n",
            "very capable performer but \"\n",
            "f not only a\n",
            "very capable performer but in the winding with a came. it is the man\n",
            "in the room with the street and\n",
            "face, out of the stoned he out to entered and seem comolice with a would provery which was no that i could not have done well, then must been all i would to the contrand which we should to see to her inforting to the word, and it was heard who will the seement and\n",
            "well, and of mr. we should not well, and we the resered to be\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"f not only a\n",
            "very capable performer but \"\n",
            "f not only a\n",
            "very capable performer but i came at seis to contrate. fadlion, lo, that the fate and intelfam cony, simon,\" i this lestreteming was\n",
            "the chanre larely and\n",
            "from evering, age'r daid which\n",
            "i. it would deal own then he was behand mr. withs on hair. oh\n",
            "wimg no thinging found out eaghes. i came him. there was\n",
            "you. but he indeeded the beliet which i\n",
            "dust had on theme me on a lance looking to foind of meseged. no were,, and vealion\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"f not only a\n",
            "very capable performer but \"\n",
            "f not only a\n",
            "very capable performer but conseluse at etled\n",
            "as mmp becalle mared out of your\n",
            "wishe all's,\n",
            "bur\n",
            "holk, for sign yoor before\n",
            "pair laer,\"\n",
            "\n",
            "\"and\n",
            "lettle ftould gill plorg.\"\n",
            "\n",
            "\"thend ord it\n",
            "as yetry with indour\n",
            "reliker becticarter', never you tw'nt in\n",
            "the you, had it idfelled mesail, what i not writy witt\n",
            "who with a deluad..\"\n",
            " limple wooded. \"all cask hulm face. that weared. \n",
            " veltraly,\" he. -\"\n",
            "night, are comiun. beg, burning bett\n",
            "\n",
            "Epoch 00002: loss improved from 1.99798 to 1.65859, saving model to weights.hdf5\n",
            "Epoch 3/5\n",
            "187265/187265 [==============================] - 217s 1ms/step - loss: 1.5676\n",
            "\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"e ignorant of his death?\"\n",
            "\n",
            "\"i have seen \"\n",
            "e ignorant of his death?\"\n",
            "\n",
            "\"i have seen to a was the standing was a little to the dear to see the bright of the clave and standing as the companion. it was a standing of the way and here was a little stand of the stand with the colour of the companion. there was a little that the bride to the companion. there was a lade to be a lade and with the stand and had been to the station. i was a little stand to the pression. there was a stand t\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"e ignorant of his death?\"\n",
            "\n",
            "\"i have seen \"\n",
            "e ignorant of his death?\"\n",
            "\n",
            "\"i have seen to little decress with the stand. there was a pit to here with his\n",
            "light had been between to her give the case a flenger that it was she ladger, and he shall be a well the banely and with the colonel still that the well stone to be see man which was a pression. it was the mack with the fleed with the lady simply at the day which with the flear of the colour of the man which had seen to a lade he h\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"e ignorant of his death?\"\n",
            "\n",
            "\"i have seen \"\n",
            "e ignorant of his death?\"\n",
            "\n",
            "\"i have seen it aftain of away to have the into to grey eyes. thiry that is in mirow he left.\"\n",
            "\n",
            "\"it was a\n",
            "on his spentlest we last stand by the chip possible.\n",
            "\n",
            "\"oh, getter, aftaive to uncostate off of hewed sorred, which ha call the expecals were invtible\n",
            "a viult.'\n",
            "\n",
            "\"seedly little pacants. i\n",
            "kawat deh poricuseds watsol, so he are myself in some pall and lay of a good. nence to be loodsmonoto-sides if you have \n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"e ignorant of his death?\"\n",
            "\n",
            "\"i have seen \"\n",
            "e ignorant of his death?\"\n",
            "\n",
            "\"i have seen too, ebsely preus in\n",
            "the copporm fimsip -contulsisapp, and he may of get whist had open follifad beiin arey minn bed so morrue eppcaime, of newrlly-geint in that mittered her would\n",
            "prawitat,\"\n",
            "said his kind vally to you besile. out how great, why pre that it was as\n",
            "friend she lad as she folinet, for stepband of inpained we asked with a atiemt, agely fore, succestar collow bricker for my all, him\n",
            "re\n",
            "\n",
            "Epoch 00003: loss improved from 1.65859 to 1.56762, saving model to weights.hdf5\n",
            "Epoch 4/5\n",
            "187265/187265 [==============================] - 216s 1ms/step - loss: 1.5145\n",
            "\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"own special subject. you look at these s\"\n",
            "own special subject. you look at these stair stark in the street of the street of the stair. i should see that the door is for the stander of the street. the street of the man who was and so that i had no man who was the convicion and the door was an examined the street and the street and the stair and the confined that i had been to the street, and the street of the street. i should be the street and for the bend that i had been the st\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"own special subject. you look at these s\"\n",
            "own special subject. you look at these should not for the bill which i wress that she has comman to the bed the man who preserted to state with the sister at her and our miss to my into a heard and looking which we expection of the back which we befoled out into the\n",
            "matter and the face is what we bellow and you see which we can until down the too father and stove the bery to be follow that the standing in a singul no expected back which\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"own special subject. you look at these s\"\n",
            "own special subject. you look at these seem to momes was for alsonps however that the door was sirqxeican quiet of the way's\n",
            "dake\n",
            "misting am yet. which use it it would be ry tell that the carfion we should\n",
            "leave to me seet inpay im with the whilk's retained. the cobfer that you was\n",
            "every dasing upon a less to could soll to be the one and gargn am i do eail from the discearned and ged stait comp\n",
            "it also comp\n",
            "of not shew han grown woswoft\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"own special subject. you look at these s\"\n",
            "own special subject. you look at these step manker when you was liw whishe st. remidness and gones to 'clear, a look a slat nimp clees withouse\n",
            "tifle dread's lander a kind for hy might on this pro?\"\n",
            "shill of siquiunts yourself the cougar. dirdboing his pechawaks, he could not visitural, in the the carriog should let o. i anlk, and it no lan, holds a time. and shimscelled and afoll, he rushl ng here's sat.\n",
            "his shuewborder he i sis very t\n",
            "\n",
            "Epoch 00004: loss improved from 1.56762 to 1.51452, saving model to weights.hdf5\n",
            "Epoch 5/5\n",
            "187265/187265 [==============================] - 214s 1ms/step - loss: 1.4903\n",
            "\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"d to-day at gravesend. well, mrs. st. cl\"\n",
            "d to-day at gravesend. well, mrs. st. clair in the man which he was struck the street and the strong and a struck the bander the street and the strong and some of the man who was a street, and the case and the street and the man which had been the man who was a strange the and a work that the corring and some of the case with a strange and street. i should not be a strange in the carriage and came and some head the street and some long \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"d to-day at gravesend. well, mrs. st. cl\"\n",
            "d to-day at gravesend. well, mrs. st. clair strange some head and stairs, and the sunch the before that\n",
            "in her before the street. i think the engain the graver in the strong and a dair. he had read the flapper to mind in the into the door and a struny. i want to the from and to me\n",
            "and which has still by her upon the course which he had\n",
            "left the cords her, then he had gone ine of the langer face and sister, and the into the carried to th\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"d to-day at gravesend. well, mrs. st. cl\"\n",
            "d to-day at gravesend. well, mrs. st. clapine entered. insuin in the assulable\n",
            "stirthanak and inforwinsom.'\n",
            "\n",
            "\"\"his seedly in the fassent, and doed and as cleary sking through him into nell us\n",
            "the wrindon when care upon\n",
            "my son proher would have father in hid through ind the aird, and\n",
            "his and the\n",
            "said. in into the chetravity\n",
            "our mest fin\n",
            "under and camem upon this other when in the\n",
            "brame which you not trap, of such phriene upon the\n",
            "locklin\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"d to-day at gravesend. well, mrs. st. cl\"\n",
            "d to-day at gravesend. well, mrs. st. claint,\n",
            "\"but her ceinmen. you he meglace and her euich for mind that inde in when a cave\n",
            "acscertave nothing mr. would instrifle in-his avodmined tenty, what is hume, in this handdwour alt both in borey man  plevinaved doneny, minstebe the whicious\n",
            "purposioned, trambow folfer mattlibed in busiles\n",
            "tond repooriann, ir you a caest, a mell in pitcliony w. hintureact intimbrounds, whitan of his dearab.\"\n",
            "\n",
            "\n",
            "\n",
            "Epoch 00005: loss improved from 1.51452 to 1.49034, saving model to weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f69121ec4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "v8-wUR3faK5T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating text\n",
        "\n",
        "Now that the algorithm is trained, it's time to test it and generate some text!"
      ]
    },
    {
      "metadata": {
        "id": "FW-0qz2paI2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_text(length, diversity):\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    for i in range(length):\n",
        "      \n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        \n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "            \n",
        "    return generated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MySTlkpUaY61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "da571739-a18c-4b89-c8fd-3ef30127ef70"
      },
      "cell_type": "code",
      "source": [
        "print(generate_text(500, 0.2))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rrible affair up.\"\n",
            "\n",
            "\"you heard nothing your be a strange the conclus and some one of the man which he shall be a surpless the man which he shall be a street of the case and some of the man which i should be the conclus an instant of the man which he had been such the strange and the conclus the man which have been the man who was a street and her the man which he should be a strange in the case and the man who was a strange of the man which he had been an and came to me the conclus an one of the matter which he strucked to me, and the\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}